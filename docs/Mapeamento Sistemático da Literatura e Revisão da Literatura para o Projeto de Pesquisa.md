# Mapeamento Sistemático da Literatura e Revisão da Literatura para o Projeto de Pesquisa

## 1. Identificação da Pesquisa

- **Tema Geral**: Sistemas Distribuídos
- **Delimitação do Tema**: Analise de Algoritmos de Busca em Sistemas Distribuídos Simulados com Spark
- **Nome do Orientador**: Ana Carolina Sokolonski Anton
- Nome do Co-orientador: João Paulo Just Peixoto
- **Aluno(a)**: Diogo Mascarenhas Ferreira Santos
- **Curso**: Bacharelado em Sistemas de Informação (BSI)
- **Data**: 17/12/2024

---

## 2. Critérios de Seleção dos Artigos e Justificativa

Os critérios utilizados, em geral, têm como base o **ano de publicação**, buscando artigos mais recentes ou com relevância para abranger uma revisão sistemática do tema. Mesmo se tratando de um assunto que sempre permeou estudos e pesquisas, os algoritmos de busca em sistemas distribuídos parecem ter sido deixados de lado enquanto ciência pura. O mesmo se aplica aos sistemas distribuídos, que ganharam mais destaque nos últimos 15 anos com a popularidade e os avanços da **computação em nuvem** (Cloud Computing) e da **Blockchain**. Dessa forma, os sistemas distribuídos continuaram avançando e sendo explorados sob diferentes perspectivas. Esse tema dialoga, sobretudo, no eixo temático de **performance** e **otimização de rotas/busca de nós em ambientes distribuídos**, sejam eles simulados, práticos ou voltados para a Internet das Coisas (IoT), especialmente no contexto do **HDFS**.

As pesquisas demonstram que algoritmos em sistemas distribuídos têm sido continuamente aprimorados desde antes da década de 1990. Muitas vezes, acredita-se que esse é um campo já consolidado, mas estudos recentes mostram que **algoritmos e abordagens modernas ainda têm raízes fundamentais**. Isso destaca sua importância e a possibilidade de contínua otimização e análise (comparação), visando atender a essa base. Assim, é possível obter um entendimento mais profundo e personalizar algoritmos para ambientes complexos em situações de tempo real, como **sistemas distribuídos**, além de selecioná-los melhor.

Algoritmos como o **MapReduce**, por exemplo, são amplamente utilizados em sistemas distribuídos, permitindo a execução eficiente de tarefas de processamento paralelo. Essa abordagem é fundamental para lidar com grandes volumes de dados e otimizar o desempenho em simulações com o **Apache Spark**, o que tem impacto direto no desenvolvimento de soluções em diferentes contextos.

Portanto, a análise comparativa proposta neste trabalho busca explorar as potencialidades e limitações dos algoritmos de busca em sistemas distribuídos simulados, promovendo insights relevantes para otimizações e aplicações em larga escala e cenários complexos.

---

## 3. Busca de Artigos

### 3.1 Palavras-chave Utilizadas

- Analysis of parallel search algorithms
- Apache Spark search algorithms
- Cluster Simulations in Spark
- Distributed computing architectures
- Efficient graph search algorithms
- Evaluating Search Algorithms
- Graph Search Algorithms in Distributed Systems
- Multithreading in distributed systems
- Parallel programming for big data
- Search algorithms distributed systems parallel
- Simulating Distributed Systems

### 3.2 Bases de Dados Consultadas

- Google Scholar
- Scielo
- IEEE Xplore
- ACM Digital Library
- ResearchGate

### 3.3 Lista de Artigos/Trabalhos Selecionados

#### Artigo 1:

**Título**: A parallelization model for performance characterization of Spark Big Data jobs on Hadoop clusters
**Autoria**: N. Ahmed, Andre L. C. Barczak, Mohammad A. Rashid, Teo Susnjak
**Ano**: 2021
**Fonte/Link**: [Journal of Big Data](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00499-7)

#### Artigo 2:

**Título**: Advanced Optimization of Fundamental Searching and Sorting Algorithms
**Autoria**: Jasrat Singh
**Ano**: 2014
**Fonte/Link**: [International Journal of Advanced Research](https://www.semanticscholar.org/paper/Advanced-Optimization-of-Fundamental-Searching-and-Singh/aff727a46aefe5833e95e3a552c71abf403898cc)

#### Artigo 3:

**Título**: A Scalable Distributed Parallel Breadth First Search Algorithm on BlueGene L
**Autoria**: Andy Yoo, Edmond Chow, Keith Henderson, William McLendon, Bruce Hendrickson, Umit Catalyurek
**Ano**: 2005
**Fonte/Link**: [IEEE Xplore](https://ieeexplore.ieee.org/document/1559977)

#### Artigo 4:

**Título**: Algoritmos e Modelos de Programação em Big Data
**Autoria**: Fabio Porto
**Ano**: 2017
**Fonte/Link**: [ResearchGate](https://www.researchgate.net/publication/360524162_Algoritmos_e_Modelos_de_Programacao_em_Big_Data)

#### Artigo 5:

**Título**: Avaliação de Desempenho entre Algoritmos Distribuídos para Mineração de Itens Frequentes no Apache Spark
**Autoria**: Felipe Alfredo Kunzler
**Ano**: 2019
**Fonte/Link**: [FEEVALE](https://tconline.feevale.br/tc/files/0001_4739.pdf)

#### Artigo 6:

**Título**: Building a Large Scale Microscopic Road Network Traffic Simulator in Apache Spark
**Autoria**: Zishan Fu, Jia Yu, Mohamed Sarwat
**Ano**: 2019
**Fonte/Link**: [IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/8788796)

#### Artigo 7:

**Título**: Comparative Analysis of Sorting and Searching Algorithms
**Autoria**: Muqarrab Qureshi, Danish Surve, Piyush Waghela, Nidhi Sakpal
**Ano**: 2024
**Fonte/Link**: [SSRN](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4815467)

#### Artigo 8:

**Título**: Desenvolvimento e Avaliação de Desempenho de um Cluster Raspberry Pi e Apache Hadoop em Aplicações Big Data
**Autoria**: Antônio José Alves Neto
**Ano**: 2023
**Fonte/Link**: [Repositório Institucional da UFS](https://ri.ufs.br/jspui/handle/riufs/19478)

#### Artigo 9:

**Título**: Distributed Cloud Computing and Distributed Parallel Computing A Review
**Autoria**: Zryan Najat Rashid, Subhi R. M. Zebari, Karzan Hussein Sharif, Karwan Jacksi
**Ano**: 2019
**Fonte/Link**: [IEEE Xplore](https://ieeexplore.ieee.org/document/8548937)

#### Artigo 10:

**Título**: Distributed Searching of Multi Dimensional Data A Performance Evaluation Study
**Autoria**: Enrico Nardelli, Fabio Barillari, Massimo Pepe
**Ano**: 1998
**Fonte/Link**: [Journal of Parallel and Distributed Computing](https://www.sciencedirect.com/science/article/abs/pii/S0743731598914289)

#### Artigo 11:

**Título**: Modeling and Simulation of Spark Streaming
**Autoria**: Jia-Chun Lin, Ming-Chang Lee, Ingrid Chieh Yu, Einar Broch Johnsen
**Ano**: 2018
**Fonte/Link**: [ARVIX](https://arxiv.org/abs/1808.09005)

#### Artigo 12:

**Título**: New and Improved Search Algorithms and Precise Analysis of Their Average Case Complexity
**Autoria**: Şahin Emrah Amrahov, Adnan Saher Mohammed, Fatih V. Çelebi
**Ano**: 2019
**Fonte/Link**: [Future Generation Computer Systems](https://www.researchgate.net/publication/330682468_New_and_improved_search_algorithms_and_precise_analysis_of_their_average-case_complexity)

#### Artigo 13:

**Título**: Otimização de Desempenho em Processamento de Consultas MapReduce
**Autoria**: Ivan Luiz Picoli, Leandro Batista de Almeida, Eduardo Cunha de Almeida
**Ano**: 2014
**Fonte/Link**: [UFPR](https://www.inf.ufpr.br/sbbd-sbsc2014/sbbd/proceedings/artigos/pdfs/128.pdf)

#### Artigo 14:

**Título**: Parallel Search Algorithms for Discrete Optimization Problems
**Autoria**: Ananth Grama, Vipin Kumar
**Ano**: 1995
**Fonte/Link**: [SpringerLink](https://link.springer.com/chapter/10.1007/BFb0035459)

#### Artigo 15:

**Título**: Performance evaluation of parallel multithreaded A\* heuristic search algorithm
**Autoria**: Basel A. Mahafzah
**Ano**: 2014
**Fonte/Link**: [Journal of Information Science](https://www.researchgate.net/publication/273590229_Performance_evaluation_of_parallel_multithreaded_A_heuristic_search_algorithm)

#### Artigo 16:

**Título**: Performance Tuning and Evaluation of Iterative Algorithms in Spark
**Autoria**: Janani Gururam
**Ano**: 2017
**Fonte/Link**: [UMD](https://www.semanticscholar.org/paper/Performance-Tuning-and-Evaluation-of-Iterative-in-Gururam/767a1c95e257c217cb31df2ffdb94dda5295bd05)

#### Artigo 17:

**Título**: Survey on High Performance Analytics of Bigdata with Apache Spark
**Autoria**: Ramkrushna C. Maheshwar, D. Haritha
**Ano**: 2016
**Fonte/Link**: [IEEE Xplore](https://ieeexplore.ieee.org/document/7831734)

---

## 4. Fichamento

Este momento da pesquisa busca oferecer uma visão geral dos trabalhos encontrados, relacionados ao tema proposto. Está dividido em 2 seções: A Seção 4.1 faz uma síntese de cada trabalho, mostrando o que foi feito em cada um desses estudos, e na Seção 4.2 são apontadas as principais características dos trabalhos encontrados, além de relacioná-las com as do trabalho proposto.

### 4.1 Síntese dos Artigos Selecionados

Apresentação de cada um dos 17 trabalhos relacionados ao tema proposto, fazendo uma síntese de cada um deles, apresentando as principais contribuições dos mesmos.

#### Artigo 1: A Parallelization Model for Performance Characterization of Spark Big Data Jobs on Hadoop Clusters

Na pesquisa, "**A parallelization model for performance characterization of Spark Big Data jobs on Hadoop clusters**", os autores **N. Ahmed, Andre L. C. Barczak, Mohammad A. Rashid e Teo Susnjak** buscaram desenvolver um novo modelo de **performance paralela** para diferentes workloads de aplicações **Spark Big Data** executadas em clusters **Hadoop**. A motivação reside na necessidade de **prever o tempo de execução** de trabalhos Spark em função do número de executores, sem depender de conhecimento prévio da implementação dos algoritmos, e **oferecer uma alternativa aos modelos de machine learning** que exigem grandes conjuntos de dados para treinamento. Para isso, propuseram um modelo baseado em **limites seriais para um arranjo 2D de executores**, análogo à simulação de calor em uma placa 2D. A equação do modelo **relaciona o tempo de execução com o número de executores e o tamanho do problema**, considerando o crescimento da porção serial do trabalho devido à comunicação e I/O entre executores. Utilizando um cluster Hadoop real com **Apache Spark e HiBench**, realizaram experimentos com workloads como **WordCount, SVM, K-means, PageRank e Graph (NWeight)**, variando o número de executores para diferentes tamanhos de dados. Analisaram o **tempo de execução** e utilizaram o **coeficiente de determinação R²** para avaliar a precisão do modelo na **curva de ajuste aos dados empíricos**.

Os autores realizaram uma comparação entre a precisão do **modelo proposto**, da **Lei de Amdahl** e da **Lei de Gustafson** na previsão do tempo de execução para cada workload. Utilizando um cluster Hadoop com 10 nós, com detalhes de hardware especificados no artigo, executaram os workloads do HiBench em diferentes configurações de executores. Foi concluído que o **modelo proposto** **atinge o melhor ajuste na maioria dos workloads e tamanhos de dados**, sendo mais preciso que as Leis de Amdahl e Gustafson em cenários onde o tempo de execução **apresenta um pico de performance para um número específico de executores**, depois crescendo com o aumento de executores. O modelo, porém, **apresenta menor precisão em workloads com tempos de execução muito curtos** (poucos segundos) e **o modelo 2D se limita à variação do número de executores**, não considerando outros parâmetros do Spark ou do cluster. Apesar das limitações, o modelo oferece uma **ferramenta simples e eficiente para prever o tempo de execução** de trabalhos Spark, auxiliando na escolha do número ideal de executores para um determinado tamanho de problema. A pesquisa contribui para o **entendimento do impacto da paralelização no desempenho de aplicações Spark**, com potencial para otimizar a utilização de recursos em clusters Hadoop.

#### Artigo 2: Advanced Optimization of Fundamental Searching and Sorting Algorithms

Nessa pesquisa, "**Advanced Optimization of Fundamental Searching and Sorting Algorithms**", o autor **Jasrat Singh** buscou **apresentar algoritmos otimizados de busca e ordenação, com foco na melhoria da eficiência e no desempenho em relação aos algoritmos fundamentais**. O autor justifica a pesquisa pela **importância da busca e ordenação como operações essenciais em estrutura de dados, que facilitam a localização e organização da informação**. A necessidade de **otimização se dá pelo fato de que os algoritmos de busca e ordenação podem ser intensivos em termos de tempo e recursos, especialmente ao lidar com grandes conjuntos de dados**. Para isso, o autor **propõe novos algoritmos de busca e ordenação, como o "OBSwQS" (Optimized Binary Search with Quick Sort), "DNSS" (Dual Nature Selection Sort), "DNBS" (Dual Nature Bubble Sort) e "ISwMS" (Insertion Sort within the Merge Sort)**. A metodologia consistiu em **descrever os algoritmos propostos**, **analisar sua complexidade de tempo e espaço**, **comparar seu desempenho com os algoritmos tradicionais** e **demonstrar sua eficácia através de exemplos e análises matemáticas**. Foram aplicados conceitos de **análise assintótica**, utilizando a notação **Big O**, para avaliar a complexidade dos algoritmos.

O autor realizou uma **comparação entre os algoritmos otimizados e seus equivalentes fundamentais**, como **Selection Sort, Bubble Sort e Merge Sort**, utilizando **métricas de desempenho como tempo de execução e número de comparações**. Os resultados da pesquisa indicam que **os algoritmos propostos, como o DNSS e o DNBS, podem reduzir o tempo de operação em até 50% em comparação com os algoritmos tradicionais, com precisão próxima a 100%**. O autor também **demonstra que o ISwMS supera o Merge Sort para valores específicos de "n" (número de itens a serem ordenados)**, **identificando um limite onde o Insertion Sort se torna mais eficiente**. A pesquisa conclui que **a otimização dos algoritmos de busca e ordenação pode levar a ganhos significativos de desempenho**, o que é **crucial para aplicações que exigem processamento eficiente de dados**. Apesar das vantagens, **o autor reconhece que os algoritmos otimizados podem ter um desempenho inferior em alguns casos específicos**, **dependendo das características dos dados e do problema em questão**. O autor sugere que futuras pesquisas explorem **a aplicação dos algoritmos propostos em diferentes cenários e conjuntos de dados**, **bem como a investigação de novas técnicas de otimização para algoritmos de busca e ordenação**.

#### Artigo 3: A Scalable Distributed Parallel Breadth First Search Algorithm on BlueGene L

Na pesquisa, "**A Scalable Distributed Parallel Breadth-First Search Algorithm on BlueGene/L**", os autores **Andy Yoo, Edmond Chow, Keith Henderson, William McLendon, Bruce Hendrickson e Ümit Çatalyürek** buscaram desenvolver um algoritmo **paralelo e distribuído** para a **Busca em Largura (BFS)** escalável para **grafos massivos**. A justificativa reside na crescente demanda por análise de grandes conjuntos de dados em áreas como genômica, astrofísica e segurança nacional, onde a busca em grafos desempenha papel crucial, e grafos com bilhões de vértices e arestas exigem processamento distribuído. Para isso, propuseram um algoritmo BFS **síncrono por nível** que utiliza **partição 2D** do grafo e **otimizações de memória e comunicação**. Utilizando o supercomputador **IBM BlueGene/L**, com **32.768 nós** no Lawrence Livermore National Laboratory, testaram a escalabilidade do algoritmo em **grafos aleatórios** com até **3 bilhões de vértices e 32 bilhões de arestas**, variando o grau médio dos vértices. Foram analisadas métricas como **tempo de execução, volume de mensagens e comprimento médio das mensagens**, comparando diferentes topologias de processadores e estratégias de particionamento (1D e 2D).

Os autores realizaram uma comparação entre o **desempenho do algoritmo BFS com particionamento 1D** e **2D**, além de comparar a **busca unidirecional** com a **bidirecional**. Utilizando o **BlueGene/L**, com sua arquitetura de **torus 3D**, exploraram otimizações de comunicação coletiva, como **reduce-scatter** para a operação de "fold". Concluiu-se que o algoritmo BFS proposto com **partição 2D** e otimizações de comunicação demonstra **alta escalabilidade**, com tempos de execução proporcionais a **log P** (onde P é o número de processadores) em testes de weak scaling. A **busca bidirecional** apresentou desempenho superior à unidirecional, reduzindo o tempo de busca e o volume de mensagens. Apesar das otimizações, o **aumento do grau médio dos vértices** impactou negativamente o desempenho, e a pesquisa se limitou a **grafos aleatórios**, não explorando grafos do mundo real com características específicas, como alto coeficiente de agrupamento. Os autores destacam que o trabalho contribui para o desenvolvimento de algoritmos escaláveis para aplicações intensivas em dados e comunicação em supercomputadores, com potencial para análise de grafos de grande escala em diversas áreas.

#### Artigo 4: Algoritmos e Modelos de Programação em Big Data

Na pesquisa, "**Algoritmos e Modelos de Programação em Big Data**", o autor **Fabio Porto** busca apresentar o **modelo de programação MapReduce e sua implementação no framework Apache Spark**, além de discutir algoritmos que auxiliam no desenvolvimento de aplicações nesse paradigma. A justificativa para essa pesquisa reside na crescente importância do **fenômeno Big Data**, caracterizado pelo grande volume, variedade e velocidade dos dados, que exigem novas abordagens de processamento e interpretação. O autor utiliza uma metodologia descritiva, explorando conceitos, arquiteturas e exemplos de aplicações. Como exemplo de aplicação, o autor detalha o **Constellation Queries (CQ)**, um projeto que busca por padrões geométricos em grandes conjuntos de dados astronômicos para identificar fenômenos como lentes gravitacionais.

O autor apresenta uma análise aprofundada da **arquitetura de processamento paralelo sem compartilhamento** adotada por frameworks MapReduce, com foco no **Hadoop File System (HDFS)** e suas características de distribuição de dados, tolerância a falhas e replicação de blocos. É discutido o modelo de programação MapReduce, com ênfase na **localidade de dados** e na otimização do processamento por meio da manutenção de arquivos intermediários em memória, como implementado no Apache Spark. O autor também explora algoritmos de particionamento de dados, como o **FRANCE**, que visa otimizar a distribuição de dados em cenários com critérios de vizinhança, e estruturas de indexação, como a **PH-Tree** e a **Randomized KD-tree**, que auxiliam na busca eficiente em grandes conjuntos de dados multidimensionais. Finalmente, o autor aborda técnicas de **clusterização**, como o **K-means**, e discute sua relevância na análise e interpretação de grandes volumes de dados. O trabalho contribui para a compreensão dos desafios e das soluções para o processamento de Big Data, com foco em algoritmos e modelos de programação que permitem a análise eficiente de grandes conjuntos de dados em diversas áreas.

#### Artigo 5: Avaliacao de Desempenho entre Algoritmos Distribuidos para Mineracao de Itens Frequentes no Apache Spark

Nessa pesquisa, "**Avaliação de Desempenho entre Algoritmos Distribuídos para Mineração de Itemsets Frequentes no Apache Spark**", o autor **Felipe Alfredo Kunzler** buscou **investigar o desempenho de três algoritmos distribuídos para mineração de itemsets frequentes (FIM) na plataforma Apache Spark**: **YAFIM, R-Apriori e DFPS**. O trabalho é motivado pelo crescente volume de dados gerados atualmente (**Big Data**) e pela necessidade de **algoritmos eficientes para extrair informações relevantes desses dados em tempo hábil**. A mineração de itemsets frequentes, um passo crucial em algoritmos de regras de associação, é **computacionalmente intensiva** e se beneficia de **implementações paralelas e distribuídas**. Para isso, o autor utilizou uma **metodologia experimental**, **implementando os algoritmos YAFIM, R-Apriori e DFPS em Scala, utilizando a API de RDDs do Spark**. Os experimentos foram conduzidos em um **cluster Amazon EMR (Elastic MapReduce)** com **instâncias m5.xlarge (2 cores, 16GB RAM)**. Foram utilizados **quatro datasets** comumente empregados em pesquisas de FIM: **Mushroom, T10I4D100K, Chess e Pumsb_star**, variando o número de nós do cluster (1, 3, 5, 7 e 9) e a replicação dos datasets (1, 3, 5, 7 e 9 vezes). Foram analisadas métricas como **tempo de execução**, e os resultados dos algoritmos foram validados com a ferramenta **SPMF**.

O autor realizou uma **comparação entre o desempenho dos algoritmos YAFIM, R-Apriori e DFPS**, **variando o volume de dados e o número de nós no cluster**. Os resultados indicam que o **DFPS, baseado no algoritmo FP-Growth, apresenta o melhor desempenho na maioria dos cenários**, superando o YAFIM e o R-Apriori, baseados no algoritmo Apriori. Essa superioridade é atribuída à **eliminação da etapa de geração de itemsets candidatos** no FP-Growth. O **R-Apriori, por sua vez, apresenta desempenho superior ao YAFIM em cenários com alto número de singletons frequentes** devido a otimizações na geração de candidatos na segunda iteração. No entanto, o DFPS **não demonstrou o melhor fator de escalabilidade** e apresentou desempenho similar aos outros algoritmos em casos com poucos itemsets frequentes. Embora o estudo tenha se limitado a datasets específicos e à plataforma Spark, o autor destaca a **importância da escolha do algoritmo de FIM adequado** considerando as características do dataset e do ambiente de execução. A pesquisa contribui para a área de **mineração de dados em larga escala**, demonstrando a viabilidade e a eficiência de algoritmos distribuídos no Apache Spark para a tarefa de mineração de itemsets frequentes.

#### Artigo 6: Building a Large Scale Microscopic Road Network Traffic Simulator in Apache Spark

Nessa pesquisa, "**Building a Large-Scale Microscopic Road Network Traffic Simulator in Apache Spark**", os autores **Zishan Fu, Jia Yu e Mohamed Sarwat** buscaram desenvolver um **simulador de tráfego de rede rodoviária microscópico e em larga escala, chamado GeoSparkSim, utilizando a plataforma Apache Spark**. O estudo é motivado pela **dificuldade em coletar dados de tráfego urbano de alta qualidade em larga escala**, e pela **limitação dos simuladores existentes**, que geralmente **não são escaláveis ​​o suficiente para produzir dados em larga escala** ou **não consideram situações de tráfego microscópicas, como semáforos, mudança de faixa e acompanhamento de carros**. Para isso, os autores propuseram uma **abordagem que integra o GeoSparkSim com o sistema de gerenciamento de dados espaciais baseado em Spark, GeoSpark**, para simular, analisar e visualizar dados de tráfego urbano em larga escala. O **GeoSparkSim converte redes de estradas em gráficos Spark e veículos simulados em VehicleRDDs**, para paralelizar cada etapa da simulação em um conjunto de transformações RDD, distribuindo eficientemente a carga de trabalho de simulação computacionalmente intensiva para todas as máquinas em um cluster. Para implementar modelos de tráfego microscópicos, o GeoSparkSim emprega um **método de particionamento de veículos com reconhecimento de simulação para particionar veículos entre diferentes máquinas**, de forma que cada máquina tenha uma carga de trabalho balanceada. O sistema foi avaliado experimentalmente **simulando os movimentos de 200 mil veículos em uma rede rodoviária muito grande (250 mil cruzamentos e 300 mil segmentos de estrada)**.

Os autores realizaram uma **comparação entre o GeoSparkSim e outros simuladores de tráfego existentes**, com foco em **escalabilidade e granularidade**. Os resultados demonstram que o **GeoSparkSim supera as soluções existentes** em termos de **capacidade de simular um grande número de veículos em uma rede rodoviária complexa**, e de **considerar detalhes microscópicos do tráfego**. A pesquisa destaca a **importância da utilização de plataformas de computação em cluster, como o Apache Spark, para lidar com a complexidade e o volume de dados envolvidos em simulações de tráfego em larga escala**. Além disso, o trabalho contribui para a área de **modelagem e simulação de tráfego**, fornecendo uma ferramenta poderosa para **analisar o impacto de mudanças na rede rodoviária, prever congestionamentos e desenvolver estratégias de gerenciamento de tráfego mais eficientes**.

#### Artigo 7: Comparative Analysis of Sorting and Searching Algorithms

Nessa pesquisa, "**Comparative Analysis of Sorting and Searching Algorithms**", os autores **Muqarrab Qureshi, Danish Surve, Piyush Waghela e Nidhi Sakpal** buscaram **apresentar e analisar diversos algoritmos de ordenação e busca, destacando suas vantagens, desvantagens e aplicações práticas**. A pesquisa é motivada pela importância da **eficiência computacional em diversas áreas**, como processamento de dados, análise e recuperação de informações. Os autores utilizaram uma **metodologia de revisão bibliográfica**, compilando informações de diversas fontes sobre algoritmos de ordenação e busca. A pesquisa aborda algoritmos como **Bubble Sort, Cocktail Sort, Comb Sort, Gnome Sort, Selection Sort, Insertion Sort, Shell Sort, Binary Tree Sort, Quick Sort, Merge Sort e Heap Sort para ordenação, e Linear Search, Binary Search, Hash Search, Interpolation Search, Exponential Search e Ternary Search para busca**. Para cada algoritmo, são descritos o funcionamento, a complexidade temporal e espacial, além de vantagens e desvantagens. Os autores também **discutem a influência das características do conjunto de dados no desempenho dos algoritmos**.

A pesquisa realiza uma **comparação detalhada entre os algoritmos**, considerando métricas como **complexidade temporal e espacial, estabilidade, adaptabilidade e escalabilidade**. Os resultados da análise indicam que **a escolha do algoritmo ideal depende das características do conjunto de dados e dos requisitos da aplicação**. Por exemplo, **Quick Sort é eficiente para grandes conjuntos de dados, enquanto Insertion Sort é mais adequado para listas pequenas**. Na busca, **Binary Search é eficiente para conjuntos de dados ordenados de tamanho médio, enquanto Hash Search é ideal para grandes conjuntos de dados**. A pesquisa conclui que a **compreensão das características, vantagens e desvantagens de cada algoritmo é crucial para a seleção e otimização de soluções computacionais eficientes**. O estudo contribui para a área de **ciência da computação**, fornecendo um guia abrangente para a **compreensão e aplicação de algoritmos de ordenação e busca em diversos cenários**.

#### Artigo 8: Desenvolvimento e Avaliação de Desempenho de um Cluster Raspberry Pi e Apache Hadoop em Aplicações Big Data

Nessa pesquisa, "**Desenvolvimento e Avaliação de Desempenho de um Cluster Raspberry Pi e Apache Hadoop em Aplicações Big Data**", o autor **Antônio José Alves Neto** buscou **desenvolver e avaliar o desempenho de um cluster Big Data de baixo custo utilizando Raspberry Pi como estrutura de hardware e Apache Hadoop como plataforma Big Data**. A pesquisa é motivada pela **crescente necessidade de processamento de Big Data**, que exige soluções de computação de alto desempenho (HPC), e pela **busca por alternativas de baixo custo** em contraponto aos supercomputadores, de alto custo e difícil manutenção. O autor justifica a escolha do **Raspberry Pi** por ser um **Single Board Computer (SBC) de baixo custo, com variedade de modelos e que permite a utilização de diversas bibliotecas de paralelismo e Big Data**. Para isso, foi utilizada uma metodologia que envolveu **levantamento bibliográfico sobre clusters Big Data de baixo custo**, **estudo qualitativo através de uma Quasi-Revisão Sistemática da Literatura**, **aquisição de nove Raspberry Pis 4B**, **desenvolvimento do cluster** e, em paralelo, **busca e estudo de soluções para validar o funcionamento do cluster**, sendo **eleitos os benchmarks Terasort e TestDFSIO**. As execuções dos benchmarks foram realizadas em **diferentes configurações do cluster (2, 4 e 8 nós escravos)** e com **diferentes tamanhos de arquivos de dados (datasets)**, além de utilizar **capacidades de armazenamento diferentes (16 GB e 128 GB)**. Para monitorar os recursos do cluster, foi utilizada **uma Raspberry Pi 3B+ com as ferramentas Zabbix (coleta de dados) e Grafana (visualização em dashboards)**.

Os resultados do **benchmark Terasort** mostraram que **o aumento do tamanho do arquivo processado exige maior capacidade de processamento no cluster**, evidenciando que **quanto mais nós, melhor o desempenho**. Já os resultados do **TestDFSIO** indicaram que **o desempenho do cluster é ligeiramente melhor com mais nós no processamento**, **embora não tenha sido possível determinar o cenário ideal**. A pesquisa concluiu que a **combinação de Raspberry Pi e Apache Hadoop pode ser uma solução robusta e eficiente para a obtenção de um cluster Big Data de baixo custo, considerando a relação custo-benefício**. O autor destaca a **influência da capacidade de armazenamento e da tecnologia do cartão de memória no desempenho do cluster**. O **monitoramento dos recursos do cluster** permitiu a **análise do consumo de hardware (CPU, memória, temperatura, etc.) e do impacto das diferentes configurações e tamanhos de arquivos**, auxiliando na manutenção do cluster. Como trabalhos futuros, o autor sugere a **realização de testes com arquivos maiores**, **utilização de outros benchmarks**, **aplicação do cluster em ambiente real**, **medição do consumo energético**, **instalação do Apache Spark** e **disponibilização do cluster na internet para fins de pesquisa**.

#### Artigo 9: Distributed Cloud Computing and Distributed Parallel Computing A Review

Nessa pesquisa, "**Distributed Cloud Computing and Distributed Parallel Computing: A Review**", os autores **Zryan Najat Rashid, Subhi R. M. Zebari, Karzan Hussein Sharif e Karwan Jacksi** buscaram **apresentar uma discussão sobre dois tópicos importantes na área de computação: processamento paralelo distribuído e computação em nuvem distribuída**. A pesquisa é motivada pela **crescente relevância da computação em nuvem e do processamento paralelo distribuído em diversas áreas**, impulsionada pela necessidade de processar grandes volumes de dados e executar tarefas complexas de forma eficiente. Para isso, foi utilizada uma **metodologia de revisão bibliográfica**, analisando e sintetizando informações de **diversos artigos científicos sobre computação em nuvem distribuída e processamento paralelo distribuído**. Os autores exploraram **aspectos como a integração dessas tecnologias em aplicações de física de alta energia (HEP)**, **os desafios do balanceamento de carga em ambientes de nuvem distribuída**, **a implementação de algoritmos de balanceamento de carga para melhorar o desempenho do sistema** e **a otimização do tempo de resposta em sistemas de computação paralela distribuída**.

A pesquisa realiza uma **análise comparativa de diferentes abordagens e algoritmos relacionados à computação em nuvem distribuída e ao processamento paralelo distribuído**, com foco em **aspectos como balanceamento de carga, escalabilidade, tolerância a falhas e eficiência**. Os autores discutem **as vantagens e desvantagens de diferentes técnicas de balanceamento de carga**, como **VectorDot, LB of VM resources scheduling strategy, Task Scheduling Based on LB e Active Clustering**, e exploram **métricas relevantes para avaliar a eficácia do balanceamento de carga**, como **throughput, overhead, fault tolerance, migration time, response time, resource utilization, scalability e cost effectiveness**. Os autores concluem que a **combinação da computação em nuvem distribuída com o processamento paralelo distribuído oferece um grande potencial para o desenvolvimento de sistemas de alto desempenho e escaláveis, capazes de lidar com as demandas crescentes de processamento de dados e execução de tarefas complexas**. A pesquisa destaca a importância de **considerar as características específicas da aplicação e do ambiente de nuvem ao selecionar e implementar algoritmos e técnicas de balanceamento de carga**, a fim de otimizar o desempenho do sistema. O estudo contribui para a área de **ciência da computação**, fornecendo um panorama abrangente sobre **computação em nuvem distribuída e processamento paralelo distribuído**, com foco em **balanceamento de carga e otimização de desempenho**.

#### Artigo 10: Distributed Searching of Multi Dimensional Data A Performance Evaluation Study

Nessa pesquisa, "**Distributed Searching of Multi-dimensional Data: A Performance Evaluation Study**", os autores **Enrico Nardelli, Fabio Barillari e Massimo Pepe** buscaram **apresentar e avaliar uma estrutura de dados para busca em conjuntos de pontos multidimensionais em ambientes distribuídos**, comparando-a com propostas anteriores. A pesquisa se justifica pelo **crescimento da computação em rede, que viabiliza aplicações em memória principal utilizando a memória de máquinas distribuídas**, e pela necessidade de **gerenciar grandes volumes de dados multiatributos em aplicações avançadas**. Para isso, foi utilizada uma **estrutura de dados baseada em uma extensão de árvores k-d, que suporta buscas exatas, parciais e por intervalo com complexidade ótima em um sentido distribuído**. A pesquisa considerou um ambiente distribuído com suporte a **multicast**, mas também demonstrou como evitar o uso dessa funcionalidade. Os autores propuseram novas medidas de desempenho para avaliar a **eficiência da distribuição da estrutura de dados em uma rede de comunicação**, denominada **eficiência de distribuição**, expressa em termos de dois índices que medem o desperdício de recursos computacionais no processamento de mensagens.

A pesquisa comparou o desempenho da estrutura de dados proposta com **estruturas de dados distribuídas existentes, como LH, RP e DRT, utilizando simulações com o pacote de software CSIM. Foram avaliados parâmetros como fator de carga, número médio de mensagens para inserção e busca, convergência e eficiência de distribuição**. Os autores concluíram que a **estrutura de dados proposta apresentou um fator de carga tão bom quanto DRT e RP, e melhor que LH**. Em relação ao **número médio de mensagens, o desempenho foi similar ao RP quando o multicast estava disponível, e não pior que DRT quando o multicast não estava disponível**. A pesquisa também concluiu que a **estrutura de dados proposta permite gerenciar e consultar conjuntos de pontos multidimensionais de forma eficiente em um ambiente distribuído**. Os autores destacam a vantagem da estrutura proposta em relação aos seus competidores por ser capaz de **gerenciar dados unidimensionais e multidimensionais, operar com e sem multicast, além de oferecer melhor tolerância a falhas de servidor**.

#### Artigo 11: Modeling and Simulation of Spark Streaming

Na pesquisa "Modeling and Simulation of Spark Streaming", os autores **Jia-Chun Lin, Ming-Chang Lee, Ingrid Chieh Yu e Einar Broch Johnsen** buscaram desenvolver um modelo executável e configurável, chamado **SSP**, para simular o **Spark Streaming**, um framework popular para processamento de dados em tempo real. A justificativa para o desenvolvimento do SSP reside na necessidade de uma ferramenta que permita aos usuários **avaliar e comparar diferentes configurações de parâmetros do Spark Streaming sem a necessidade de implantar suas aplicações em um cluster real**. O SSP foi escrito em **ABS**, uma linguagem formal e executável para modelagem de sistemas distribuídos.

Os autores realizaram uma comparação entre o **desempenho simulado pelo SSP** e o **desempenho observado do Spark Streaming** em um **cluster YARN** executando **Hadoop 2.2.0** e **Spark 1.5.1**. O **SSP** foi configurado para simular um cluster com 30 nós trabalhadores, cada um com 2 núcleos de CPU e 2 GB de memória, espelhando a configuração do cluster YARN. Para os testes, foi utilizada a aplicação **JavaNetworkWordCount**, que consiste em um job com duas etapas sequenciais para contar as ocorrências de cada palavra em fluxos de dados. Os dados foram enviados continuamente do site da Wikipedia do Apache Spark para a aplicação, utilizando o **Netcat**. Foi concluído que o **SSP é capaz de imitar o Spark Streaming em diferentes cenários**, capturando propriedades chave como a geração de batches, o processamento de batches vazios e não vazios, e o agendamento de batches. Os autores destacam que o SSP permite aos usuários **prever o desempenho de suas aplicações** com diferentes configurações do Spark Streaming, **auxiliando na escolha de configurações mais eficientes**. Como trabalho futuro, os autores pretendem estender o SSP para considerar aplicações com múltiplos jobs e modelar o Spark Streaming em nível de bloco.

#### Artigo 11: New and Improved Search Algorithms and Precise Analysis of Their Average Case Complexity

Nessa pesquisa, "**New and Improved Search Algorithms and Precise Analysis of Their Average Case Complexity**", os autores **Şahin Emrah Amrahov, Adnan Saher Mohammed e Fatih V. Çelebi** buscaram **analisar e aprimorar algoritmos de busca em sequências ordenadas, com foco na redução do número médio de comparações**. A pesquisa é motivada pela **importância da otimização de algoritmos de busca, especialmente com o aumento do volume de dados**, e pela necessidade de **explorar alternativas ao algoritmo de Busca Binária (BS), que apesar de sua eficiência, possui limitações em termos de desempenho médio**. Para isso, foi utilizada uma **metodologia de análise matemática precisa para calcular o número médio de comparações de diferentes algoritmos de busca, incluindo implementações do algoritmo BS, uma versão aprimorada do algoritmo de Busca Ternária (ITS) e um novo algoritmo de Busca Binária-Quaternária (BQS)**. Os autores também realizaram **experimentos para validar os resultados teóricos e comparar o desempenho dos algoritmos em diferentes cenários**. Foram analisadas **métricas como o número de comparações, tempo de execução e a influência do tipo de dado e do tamanho da sequência ordenada no desempenho dos algoritmos**.

A pesquisa realiza uma **comparação detalhada entre diferentes implementações do algoritmo BS**, identificando uma **implementação "fraca" com desempenho inferior à implementação "correta"** em termos do número médio de comparações. Os autores propõem o **algoritmo ITS, que aprimora o algoritmo de Busca Ternária tradicional, reduzindo o número médio de comparações** . Além disso, **propõem o algoritmo BQS, que utiliza uma estratégia de divisão inovadora, dividindo a sequência ordenada em 2 ou 4 partes, com base na posição da chave de busca** . **Os resultados teóricos e experimentais demonstram que o ITS e o BQS apresentam um número médio de comparações menor que a implementação correta do BS**, sendo o **BQS mais eficiente que o ITS em cenários onde o custo da operação de comparação é menor que o custo da operação de divisão** . A pesquisa conclui que **o ITS e o BQS são alternativas eficientes ao algoritmo BS, com potencial para melhorar o desempenho de busca em sequências ordenadas**. Os autores destacam a **importância da escolha do algoritmo de busca adequado, considerando as características da aplicação e o custo das operações de comparação e divisão**.

#### Artigo 13: Otimização de Desempenho em Processamento de Consultas MapReduce

Nessa pesquisa, "**Otimização de Desempenho em Processamento de Consultas MapReduce**", os autores **Ivan Luiz Picoli, Leandro Batista de Almeida e Eduardo Cunha de Almeida** buscaram **abordar os esforços atuais e as formas de otimização de desempenho de _data warehouses_ baseados em MapReduce, com foco principal em uma solução baseada em Hadoop, Hive e AutoConf**. O estudo se justifica pelo **crescimento exponencial da quantidade de dados armazenados na rede mundial na última década**, impulsionado pela popularização da internet, redes sociais, sistemas em nuvem e _business intelligence_, que exigem **escalabilidade dos sistemas de armazenamento e processamento de dados**. Para isso, os autores **apresentam uma revisão da literatura sobre Big Data, MapReduce, Hadoop, Hive e técnicas de otimização de consultas**, com ênfase na **importância do ajuste de parâmetros de configuração do sistema para a eficiência das aplicações MapReduce**. A pesquisa **discute diferentes abordagens de otimização**, como o **Starfish**, que **sugere configurações de parâmetros**, e o **AutoConf**, que **analisa os operadores da consulta para ajustar os parâmetros em tempo de execução**. Os autores também **propõem o uso de aprendizado de máquina não supervisionado, especificamente o algoritmo K-Means, para analisar logs de tarefas MapReduce e identificar padrões de comportamento**, visando **criar grupos de tarefas com características semelhantes e otimizar o desempenho com base nesses grupos**.

Os autores **apresentam o Chameleon, uma ferramenta de autoajuste de desempenho que utiliza o algoritmo K-Means sobre os logs de execução do Hadoop para complementar o AutoConf na otimização de consultas do Hive**. O Chameleon **analisa os logs para identificar grupos de comportamento, que representam o consumo real de recursos das máquinas, e associa esses grupos às assinaturas de código do AutoConf**. Dessa forma, **o Chameleon ajusta os parâmetros de configuração de acordo com o grupo de comportamento da tarefa**, buscando **uma otimização mais precisa e eficiente**. A pesquisa **conclui que a otimização de consultas MapReduce é uma área de pesquisa em constante desenvolvimento**, com **grande potencial para aprimorar o desempenho de sistemas de processamento de dados em larga escala**. Os autores **destacam a importância de abordagens que combinem análise de consultas, logs de execução e aprendizado de máquina para alcançar resultados mais eficazes** e **incentivam a comunidade científica a investir em pesquisas nessa área**.

#### Artigo 14: Parallel Search Algorithms for Discrete Optimization Problems

Nessa pesquisa, "**Parallel Search Algorithms for Discrete Optimization Problems**", os autores **Ananth Grama e Vipin Kumar** buscaram **explorar e apresentar algoritmos de busca paralela para a resolução de problemas de otimização discreta, analisando a eficiência, a escalabilidade e a aplicabilidade em diferentes arquiteturas paralelas**. A pesquisa se justifica pela **crescente demanda por soluções computacionais eficientes para problemas de otimização complexos**, com a **busca por algoritmos paralelos que explorem o poder de processamento de arquiteturas de computação paralelas**. Para isso, **os autores apresentam uma revisão abrangente de algoritmos de busca paralela**, incluindo **abordagens baseadas em decomposição de espaço de busca, como _branch-and-bound_, e abordagens baseadas em população, como algoritmos genéticos**. A pesquisa **discute os desafios e as oportunidades da paralelização de algoritmos de busca**, com **ênfase na comunicação entre processadores, balanceamento de carga, granularidade da paralelização e tolerância a falhas**. **São analisadas as características de diferentes arquiteturas paralelas**, como **sistemas de memória compartilhada, sistemas de memória distribuída e redes de interconexão**, e **sua influência no desempenho dos algoritmos de busca paralela**.

Os autores **demonstram a aplicação de algoritmos de busca paralela em diversos problemas de otimização discreta**, como **o problema do caixeiro viajante, o problema da mochila e o problema de alocação de tarefas**. **Os resultados experimentais**, obtidos em diferentes arquiteturas paralelas, **comprovam a eficiência e a escalabilidade dos algoritmos de busca paralela, com ganhos significativos de desempenho em relação às abordagens sequenciais**. A pesquisa **conclui que a paralelização de algoritmos de busca é uma técnica promissora para a resolução eficiente de problemas de otimização discreta**, com **potencial para lidar com instâncias de problemas cada vez maiores e mais complexas**. Os autores **destacam a importância da escolha adequada do algoritmo de busca, da arquitetura paralela e da estratégia de paralelização para maximizar o desempenho**.

#### Artigo 15: Performance evaluation of parallel multithreaded A\* heuristic search algorithm

Nessa pesquisa, **"Performance Evaluation of Parallel Multithreaded A\* Heuristic Search Algorithm"**, o autor **Basel A. Mahafzah** buscou **projetar, implementar e avaliar um algoritmo de busca heurística A\* paralelo e multithreaded para resolver o problema do quebra-cabeça de 15**. O autor justifica a pesquisa pela necessidade de **aprimorar o desempenho dos algoritmos de busca heurística, especialmente em problemas complexos de larga escala, e pelo potencial da técnica de multithreading em reduzir o tempo de execução e simplificar a comunicação entre threads**. Para isso, **implementou uma abordagem genérica de multithreading utilizando a biblioteca POSIX Threads (Pthreads) para paralelizar o algoritmo A\***.

A metodologia consistiu em **analisar o algoritmo proposto em termos de complexidade de tempo e espaço, completude e otimização**. O estudo também envolveu a **comparação do algoritmo multithreaded com sua contraparte sequencial em termos de métricas de desempenho, incluindo speedup, número de nós gerados e expandidos, número de verificações de duplicatas e efetividade da busca**.

O autor realizou experimentos com o algoritmo multithreaded A\* em um computador **dual-core com tecnologia Hyper-Threading**, utilizando o problema do **quebra-cabeça de 15 como domínio de busca**. O sistema contava com **2 GB de RAM, 3 MB de cache L2 e rodava o sistema operacional SUSE Linux versão 10**. Os algoritmos, tanto o sequencial quanto o paralelo multithreaded, foram implementados em **linguagem C, utilizando a biblioteca GNU C versão 2.3.x (glibc 2.3.x)**. **O número de threads concorrentes variou de 7 a 120, compartilhando os quatro threads de hardware SMT**.

Os resultados experimentais demonstraram que o algoritmo A\* multithreaded obteve um desempenho significativamente melhor do que o algoritmo A\* sequencial em termos de speedup, especialmente em problemas de grande escala. **A pesquisa concluiu que a multithreading é uma abordagem viável para a paralelização de algoritmos de busca heurística, proporcionando melhor desempenho em termos de complexidade de tempo e speedup**. O autor destaca que, apesar do aumento no número de nós gerados e expandidos pelo algoritmo multithreaded, a técnica se mostra promissora para lidar com problemas de busca complexos.

Sugere-se que futuras pesquisas explorem a implementação do algoritmo com outras bibliotecas de multithreading, como Java threads, e avaliem seu desempenho em diferentes arquiteturas de hardware. Além disso, o autor recomenda a aplicação do algoritmo em outros problemas de busca e domínios de aplicação, como o problema do caixeiro viajante e mecanismos de busca na web.

#### Artigo 16: Performance Tuning and Evaluation of Iterative Algorithms in Spark

Nessa pesquisa, "**Performance Tuning and Evaluation of Iterative Algorithms in Spark**", a autora **Janani Gururam** buscou **discutir as características-chave do Spark que o diferenciam de outras estruturas MapReduce**, com foco em **como os algoritmos iterativos são implementados e otimizados**. A pesquisa se justifica pela **ampla adoção do Spark em diversas áreas de aplicação**, o que impulsiona a **necessidade de ferramentas adequadas para otimizar seu desempenho**. Para isso, a autora **analisa o impacto do armazenamento em cache de RDDs (Resilient Distributed Datasets), da serialização, da E/S de disco e de outras considerações de parâmetros na melhoria do desempenho do Spark**. A pesquisa **aborda a tolerância a falhas no Spark em comparação com outras estruturas de processamento de dados populares**, como **Google MapReduce, Dryad, Apache Tez, Pregel e Apache Flink**. Também **explora a implementação de algoritmos iterativos** e os **desafios específicos que eles apresentam em sistemas de fluxo de dados**, como o **crescimento de grafos de linhagem e o impacto da imutabilidade dos RDDs na eficiência computacional**.

A pesquisa **apresenta uma análise detalhada de algoritmos iterativos selecionados e sua implementação e desempenho no Spark**, incluindo **PageRank, K-means Clustering e Connected Components**. São discutidas **técnicas de otimização para cada algoritmo**, como **o uso de RDD caching, particionamento de vértices baseado em hash e combinadores para PageRank, e a manutenção de visão incremental para Connected Components**. A autora também **discute ferramentas de benchmarking disponíveis para Spark e estruturas semelhantes**, incluindo **ferramentas específicas de estrutura como HiBench e Spark-perf, e ferramentas de múltiplas estruturas como BigDataBench e BigBench**. A pesquisa **conclui que a caracterização completa da carga de trabalho é fundamental para entender as implicações de desempenho das aplicações Spark**, e que **a compreensão de se uma carga de trabalho é vinculada à CPU ou ao disco é essencial para determinar a eficácia de técnicas de otimização**. A autora **destaca a necessidade de ferramentas de benchmarking eficazes que permitam aos usuários tomar decisões informadas sobre otimização de desempenho**, e **sugere trabalhos futuros no desenvolvimento de um ambiente de depuração interativo e intuitivo para Spark**, similar ao Pig Pen.

#### Artigo 17 Survey on High Performance Analytics of Bigdata with Apache Spark

Nessa pesquisa, "**Survey on High Performance Analytics of Bigdata with Apache Spark**", os autores **Ramkrushna C., Maheshwar D. e Haritha D.** buscaram **demonstrar as vantagens do Apache Spark sobre o Hadoop MapReduce na análise de Big Data, com foco na análise de dados em tempo real usando análise de séries temporais**. A pesquisa se justifica pela **crescente necessidade de processar e analisar grandes volumes de dados em tempo real**, e as **limitações do Hadoop MapReduce em termos de latência, tolerância a falhas e processamento iterativo**. Para isso, os autores **apresentam uma revisão abrangente da arquitetura, dos recursos e das capacidades do Apache Spark**, com **ênfase em seus componentes principais, como Spark Core, Spark SQL, Spark Streaming, MLlib e GraphX**. **É discutida a capacidade do Spark de realizar processamento na memória, o que contribui para seu desempenho superior em relação ao Hadoop MapReduce**. A pesquisa **explora o conceito de RDDs (Resilient Distributed Datasets) e sua importância na tolerância a falhas e na eficiência do Spark**. Também **é abordada a integração do Spark com a linguagem R para análise estatística, utilizando a biblioteca SparkR**.

Os autores **demonstram a aplicação do Spark e da análise de séries temporais em cenários do mundo real, como análise de dados meteorológicos e previsão do tempo**. **São apresentados exemplos de como o Spark pode ser usado para processar e analisar dados de séries temporais para extrair insights significativos e gerar previsões**. A pesquisa **conclui que o Apache Spark é uma ferramenta poderosa e eficiente para análise de Big Data, oferecendo vantagens significativas sobre o Hadoop MapReduce em termos de desempenho, escalabilidade e capacidade de lidar com dados em tempo real**. Os autores **destacam a importância do Spark na análise de séries temporais**, que **permite a extração de padrões e tendências ocultas em dados sequenciais, com aplicações em diversas áreas, como finanças, saúde e meteorologia**. A pesquisa **sugere que o Spark continuará a desempenhar um papel fundamental na evolução da análise de Big Data**, impulsionado por sua capacidade de lidar com a crescente complexidade e volume dos dados, e sua capacidade de integrar diferentes ferramentas e tecnologias, como aprendizado de máquina e processamento de grafos.

### 4.2 Relação dos Artigos

Pendente

### 5. Esquema da Fundamentação Teórica

Pendente
